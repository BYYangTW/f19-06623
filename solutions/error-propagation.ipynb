{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have fit a model to some data like we did in lecture 11. If the model is: $f(x) = \\frac{a x}{b + x}$ and it is given that $a = 1.33 \\pm 0.01$ and $b = 0.03 \\pm 0.001$. The uncertainty in the prediction of $f(x)$ can be estimated as\n",
    "\n",
    "$\\sigma_f = \\sqrt{(\\frac{\\partial f}{\\partial a})^2 \\sigma_a^2 + (\\frac{\\partial f}{\\partial b})^2 \\sigma_b^2}$\n",
    "\n",
    "evaluated at the point you want to make a prediction on. Use these formulas to estimate $f(5)$ and the 95% confidence  $f(5)$. Note that you should get a similar answer as what is in the lecture notes. You do not need to use the Student t-table in this problem, just estimate $\\sigma_f$ and with that a 95% confidence interval.\n",
    "\n",
    "I recommend that you try to use `scipy.misc.derivative`, but you can also derive the partial derivatives by hand if you prefer.\n",
    "\n",
    "Provide a discussion comparing this approach to the one in the lecture notes, including one advantage and one disadvantage of each approach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to do this is to use a numerical derivative with scipy.misc.derivative. The main tricky part of this is how to get functions it can use because it only takes the derivative of the first argument. We can write helper functions that have the argument we want first, and that return the function value we need for that purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value is at x=5 is 1.322 +/- 0.020 at the 95% confidence level\n"
     ]
    }
   ],
   "source": [
    "from scipy.misc import derivative\n",
    "import numpy as np\n",
    "\n",
    "def f(x, a, b):\n",
    "    return a * x / (b + x)\n",
    "\n",
    "def fa(a, x, b):\n",
    "    return f(x, a, b)\n",
    "\n",
    "def fb(b, x, a):\n",
    "    return f(x, a, b)\n",
    "\n",
    "\n",
    "\n",
    "X = 5\n",
    "a = 1.33\n",
    "b = 0.03\n",
    "sigma_a = 0.01\n",
    "sigma_b = 0.001\n",
    "\n",
    "dfda = derivative(fa, a, args=(X, b))\n",
    "dfdb = derivative(fb, b, args=(X, a))\n",
    "\n",
    "print(f'The value is at x=5 is {f(5, a, b):1.3f} +/- {2 * np.sqrt(dfda**2 * sigma_a**2 + dfdb**2 * sigma_b**2):1.3f} at the 95% confidence level')\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is practically the same as we saw in the lecture notes. Here we did not have to do the Monte Carlo approach, which can be time consuming. The code for getting the derivatives is short, but requires some helper functions to get the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method in this assignment assumes normal distribution and it is more suitable when the number of data used to fit the model is large (n>30)\n",
    "The method with t-test in the lecture assumes t-distribution and it is more suitable when the number of data is small (n<30). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use numdifftools for this. This also required some understanding of how to get the desired results from the Gradient. Here you have to read the docs of Gradient to see that it can take the derivative with respect to an array as the first argument. So we rewrite our function and then we get three derivatives. These basically have the same values  as the ones above. Small differences are there, and since these are both approximations you would have to do some numerical investigations of convergence of some default parameters in the algorithms like the finite difference spacing, order of the difference formula etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0.99403579     0.99403579\n",
      "    -0.27365242    -0.26283650\n",
      "The value is at x=5 is 1.322 +/- 0.020 at the 95% confidence level\n"
     ]
    }
   ],
   "source": [
    "import numdifftools as nd\n",
    "\n",
    "def F(X):\n",
    "    x, a, b = X\n",
    "    return a * x / (b + x)\n",
    "\n",
    "df = nd.Gradient(F)\n",
    "dFdx, dFda, dFdb = df([5, a, b])\n",
    "\n",
    "print(f'{dfda:15.8f}{dFda:15.8f}')\n",
    "print(f'{dfdb:15.8f}{dFdb:15.8f}') # These are a little different, but not much\n",
    "\n",
    "print(f'The value is at x=5 is {F([5, a, b]):1.3f} +/- {2 * np.sqrt(dFda**2 * sigma_a**2 + dFdb**2 * sigma_b**2):1.3f} at the 95% confidence level')\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
